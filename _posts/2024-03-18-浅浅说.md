---
layout: post
title: 浅浅说...
date: 2024-03-18
toc: true
password: 1127
---
首先查看了一下GPU的使用情况，发现除了GPU0以外都还能再用一用...
![](https://raw.githubusercontent.com/MingYangi/MingYangi.github.io/master/images/multi-gpus/nvidia-smi.png)
首先查看了一下GPU的使用情况，发现除了GPU0以外都还能再用一用...

![](https://raw.githubusercontent.com/MingYangi/MingYangi.github.io/master/images/multi-gpus/nvidia-smi.png)

![](https://raw.githubusercontent.com/MingYangi/MingYangi.github.io/master/images/multi-gpus/nvidia-smi2.png)

然后尝试着用GPU 1,2,3卡进行训练，并且确认代码已经识别使用GPU 1,2,3卡进行训练了：

![](https://raw.githubusercontent.com/MingYangi/MingYangi.github.io/master/images/multi-gpus/GPUs.png)

![](https://raw.githubusercontent.com/MingYangi/MingYangi.github.io/master/images/multi-gpus/GPU123.png)

### 问题

但是，问题来了，明明指定了GPU 1,2,3，但是仍然显示使用的是GPU0在分配资源！！！
![](https://raw.githubusercontent.com/MingYangi/MingYangi.github.io/master/images/multi-gpus/problem.png)

查看了代码，batch size=1了都仍然不行，尝试一溜十三招还是没能解决问题。其实是并不懂得问题真正所在。<br>

### 解决方案

最后发现！！！**在指定 `os.environ['CUDA_VISIBLE_DEVICES'] = '1,2,3'`时，一定要在`import torch`之前添加，我进一步理解为应该在所有要用到GPU的变量之前添加，否则默认给torch分配的就是GPU0！！！**

![](https://raw.githubusercontent.com/MingYangi/MingYangi.github.io/master/images/multi-gpus/solution.png)

**PS：**`os.environ['CUDA_VISIBLE_DEVICES'] = '1,2,3'`和`os.environ['CUDA_VISIBLE_DEVICES'] = '2,1,3'`是不同的表示，分配GPU具有顺序性，排在前面的会优先分配资源。如果GPU1显存不足，那么`os.environ['CUDA_VISIBLE_DEVICES'] = '1,2,3'`这种分配方式是会报错的。
